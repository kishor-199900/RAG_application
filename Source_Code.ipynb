{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jadha\\AppData\\Local\\Temp\\ipykernel_22420\\1342716416.py:17: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "# Onboarding Questions\n",
    "onboarding_questions = [\n",
    "    {\"id\": 1, \"question\": \"What is your full name?\", \"field\": \"name\"},\n",
    "    {\"id\": 2, \"question\": \"What is your contact number?\", \"field\": \"contact_number\"},\n",
    "    {\"id\": 3, \"question\": \"What is your email address?\", \"field\": \"email\"},\n",
    "    {\"id\": 4, \"question\": \"What is your business name?\", \"field\": \"business_name\"},\n",
    "    {\"id\": 5, \"question\": \"What type of business do you run?\", \"field\": \"business_type\"},\n",
    "    {\"id\": 6, \"question\": \"How many employees does your company have?\", \"field\": \"company_size\"},\n",
    "    {\"id\": 7, \"question\": \"Where is your company located?\", \"field\": \"company_location\"},\n",
    "    {\"id\": 8, \"question\": \"What is your company's website?\", \"field\": \"company_website\"}\n",
    "]\n",
    "\n",
    "# Database Schema (using SQLAlchemy as an example)\n",
    "from sqlalchemy import create_engine, Column, Integer, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    contact_number = Column(String)\n",
    "    email = Column(String, unique=True)\n",
    "    business_name = Column(String)\n",
    "    business_type = Column(String)\n",
    "    company_size = Column(String)\n",
    "    company_location = Column(String)\n",
    "    company_website = Column(String)\n",
    "\n",
    "# Set up the database\n",
    "engine = create_engine('sqlite:///onboarding.db')\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Build a Conversational Agent with LangChain and Llama Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from llama_index import SimpleDirectoryReader, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from onboarding_questions_schema import User, onboarding_questions\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Initialize LangChain\n",
    "llm = OpenAI(temperature=0.7)\n",
    "template = \"\"\"\n",
    "You are an AI assistant helping with user onboarding. Ask the user the following question:\n",
    "{question}\n",
    "Current conversation:\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"chat_history\", \"human_input\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "conversation = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# Initialize Llama Index\n",
    "def create_index(directory_path):\n",
    "    max_input_size = 4096\n",
    "    num_outputs = 512\n",
    "    max_chunk_overlap = 20\n",
    "    chunk_size_limit = 600\n",
    "\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.7, model_name=\"text-davinci-002\", max_tokens=num_outputs))\n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    index = GPTSimpleVectorIndex(documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "    index.save_to_disk('index.json')\n",
    "    return index\n",
    "\n",
    "# Load or create the index\n",
    "index_file = 'index.json'\n",
    "if os.path.exists(index_file):\n",
    "    index = GPTSimpleVectorIndex.load_from_disk(index_file)\n",
    "else:\n",
    "    index = create_index('path/to/your/documents')\n",
    "\n",
    "# Set up database connection\n",
    "engine = create_engine('sqlite:///onboarding.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def ask_question(question):\n",
    "    response = conversation.predict(question=question, human_input=\"\")\n",
    "    return response.strip()\n",
    "\n",
    "def store_response(field, value):\n",
    "    user = session.query(User).first()\n",
    "    if not user:\n",
    "        user = User()\n",
    "        session.add(user)\n",
    "    setattr(user, field, value)\n",
    "    session.commit()\n",
    "\n",
    "def onboarding_process():\n",
    "    print(\"Welcome to the onboarding process!\")\n",
    "    for question in onboarding_questions:\n",
    "        response = ask_question(question['question'])\n",
    "        print(f\"AI: {response}\")\n",
    "        user_input = input(\"Human: \").strip()\n",
    "        \n",
    "        # Use Llama Index to get additional information if needed\n",
    "        if user_input.lower() == \"help\":\n",
    "            query = f\"Provide more information about {question['field']}\"\n",
    "            result = index.query(query)\n",
    "            print(f\"AI: Here's some additional information: {result}\")\n",
    "            user_input = input(\"Human: \").strip()\n",
    "        \n",
    "        store_response(question['field'], user_input)\n",
    "        memory.chat_memory.add_user_message(user_input)\n",
    "    \n",
    "    print(\"Thank you for completing the onboarding process!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    onboarding_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Implement Retrieval-Augmented Generation RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from onboarding_questions_schema import User, onboarding_questions\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Initialize LangChain components\n",
    "llm = OpenAI(temperature=0.7)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Load and prepare the knowledge base\n",
    "def load_knowledge_base(directory: str) -> List[str]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            loader = TextLoader(os.path.join(directory, filename))\n",
    "            documents.extend(loader.load())\n",
    "    \n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts\n",
    "\n",
    "# Create FAISS index\n",
    "def create_faiss_index(texts: List[str]) -> FAISS:\n",
    "    return FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Set up RAG\n",
    "def setup_rag(index: FAISS) -> RetrievalQA:\n",
    "    retriever = index.as_retriever(search_kwargs={\"k\": 2})\n",
    "    return RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "# Initialize database\n",
    "engine = create_engine('sqlite:///onboarding.db')\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Load knowledge base and create index\n",
    "knowledge_base_dir = \"path/to/your/knowledge_base\"\n",
    "texts = load_knowledge_base(knowledge_base_dir)\n",
    "faiss_index = create_faiss_index(texts)\n",
    "\n",
    "# Set up RAG\n",
    "rag = setup_rag(faiss_index)\n",
    "\n",
    "# Onboarding conversation\n",
    "def onboarding_conversation():\n",
    "    template = \"\"\"\n",
    "    You are an AI assistant helping with user onboarding. Ask the user the following question:\n",
    "    {question}\n",
    "    Current conversation:\n",
    "    {chat_history}\n",
    "    Human: {human_input}\n",
    "    AI: \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\", \"chat_history\", \"human_input\"],\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    conversation = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    chat_history = []\n",
    "\n",
    "    print(\"Welcome to the onboarding process!\")\n",
    "    for question in onboarding_questions:\n",
    "        while True:\n",
    "            response = conversation.predict(question=question['question'], chat_history=\"\\n\".join(chat_history), human_input=\"\")\n",
    "            print(f\"AI: {response}\")\n",
    "            user_input = input(\"Human: \").strip()\n",
    "            \n",
    "            if user_input.lower() == \"help\":\n",
    "                help_response = rag.run(f\"Provide more information about {question['field']}\")\n",
    "                print(f\"AI: {help_response}\")\n",
    "            elif user_input.lower() == \"done\":\n",
    "                store_response(question['field'], user_input)\n",
    "                chat_history.append(f\"Human: {user_input}\")\n",
    "                chat_history.append(f\"AI: Thank you. Let's move on to the next question.\")\n",
    "                break\n",
    "            else:\n",
    "                store_response(question['field'], user_input)\n",
    "                chat_history.append(f\"Human: {user_input}\")\n",
    "                chat_history.append(f\"AI: Thank you for providing that information.\")\n",
    "                break\n",
    "\n",
    "    print(\"Onboarding process completed. Do you have any other questions?\")\n",
    "    while True:\n",
    "        user_input = input(\"Human: \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = rag.run(user_input)\n",
    "        print(f\"AI: {response}\")\n",
    "\n",
    "def store_response(field, value):\n",
    "    user = session.query(User).first()\n",
    "    if not user:\n",
    "        user = User()\n",
    "        session.add(user)\n",
    "    setattr(user, field, value)\n",
    "    session.commit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    onboarding_conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
